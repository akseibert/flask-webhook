import os
import sys
import io
import json
import re
import requests
import logging
import signal
from datetime import datetime
from time import time
from typing import Dict, Any, List, Optional, Callable
from flask import Flask, request
from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential
from difflib import SequenceMatcher
from collections import deque
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
from decouple import config

# --- Configuration ---
CONFIG = {
    "SESSION_FILE": config("SESSION_FILE", default="/opt/render/project/src/session_data.json"),
    "PAUSE_THRESHOLD": config("PAUSE_THRESHOLD", default=300, cast=int),
    "MAX_HISTORY": config("MAX_HISTORY", default=10, cast=int),
    "OPENAI_MODEL": config("OPENAI_MODEL", default="gpt-3.5-turbo"),
    "OPENAI_TEMPERATURE": config("OPENAI_TEMPERATURE", default=0.2, cast=float),
}

REQUIRED_ENV_VARS = ["OPENAI_API_KEY", "TELEGRAM_BOT_TOKEN"]

for var in REQUIRED_ENV_VARS:
    if not config(var, default=None):
        raise EnvironmentError(f"Missing required environment variable: {var}")

TELEGRAM_TOKEN = config("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = config("OPENAI_API_KEY")

# --- Logger Setup ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("ConstructionBot")

def log_event(event: str, **kwargs) -> None:
    logger.info({"event": event, **kwargs})

# --- Field Mapping ---
FIELD_MAPPING = {
    'site': 'site_name', 'sites': 'site_name',
    'segment': 'segment', 'segments': 'segment',
    'category': 'category', 'categories': 'category',
    'company': 'company', 'companies': 'company',
    'person': 'people', 'people': 'people', 'persons': 'people', 'peoples': 'people',
    'role': 'roles', 'roles': 'roles',
    'tool': 'tools', 'tools': 'tools',
    'service': 'service', 'services': 'service',
    'activity': 'activities', 'activities': 'activities',
    'issue': 'issues', 'issues': 'issues',
    'time': 'time', 'times': 'time',
    'weather': 'weather', 'weathers': 'weather',
    'impression': 'impression', 'impressions': 'impression',
    'comment': 'comments', 'comments': 'comments'
}

# --- Regex Patterns ---
FIELD_PATTERNS = {
    "site_name": r'^(?:(?:add|insert)\s+sites?\s+|sites?\s*[:,]?\s*|location\s*[:,]?\s*|project\s*[:,]?\s*)([^,]+?)(?=(?:\s*,\s*(?:segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)',
    "segment": r'^(?:(?:add|insert)\s+segments?\s+|segments?\s*[:,]?\s*)([^,.\s]+)(?=(?:\s*,\s*(?:site|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*\.)',
    "category": r'^(?:(?:add|insert)\s+categories?\s+|categories?\s*[:,]?\s*)([^,.\s]+)(?=(?:\s*,\s*(?:site|segment|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*\.)',
    "impression": r'^(?:(?:add|insert)\s+impressions?\s+|impressions?\s*[:,]?\s*)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|comments)\s*:)|$|\s*$)',
    "people": r'^(?:(?:add|insert)\s+(?:peoples?|persons?)\s+|(?:peoples?|persons?)\s*[:,]?\s*|(?:add|insert)\s+([^,]+?)\s+as\s+(?:peoples?|persons?)\s*)([^,\s]+(?:\s+[^,\s]+)*)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)',
    "role": r'^(?:(?:add|insert)\s+(?:peoples?|persons?)\s+)?(\w+\s+\w+|\w+)\s*[:,]?\s*as\s+([^,\s]+)(?:\s+to\s+(?:peoples?|persons?))?(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)|^(?:add|insert)\s*(?:persons?|peoples?)\s*[:,]?\s*(\w+\s+\w+|\w+)\s*,\s*roles?\s*[:,]?\s*([^,\s]+)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)',
    "supervisor": r'^(?:(?:add|insert)\s+roles?\s*[:,]?\s*supervisor\s*|roles?\s*[:,]?\s*supervisor\s*|i\s+(?:was\s+supervising|am\s+supervising|supervised))(?:\s+by\s+([^,]+?))?(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)',
    "company": r'^(?:(?:add|insert)\s+compan(?:y|ies)\s+|compan(?:y|ies)\s*[:,]?\s*|(?:add|insert)\s+([^,]+?)\s+as\s+compan(?:y|ies)\s*)[:,]?\s*([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)',
    "service": r'^(?:(?:add|insert)\s+services?\s+|services?\s*[:,]?\s*|services?\s*(?:were|provided)\s+)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)',
    "tool": r'^(?:(?:add|insert)\s+tools?\s+|tools?\s*[:,]?\s*|tools?\s*used\s*(?:included|were)\s+)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)',
    "activity": r'^(?:(?:add|insert)\s+activit(?:y|ies)\s+|activit(?:y|ies)\s*[:,]?\s*|activit(?:y|ies)\s*(?:covered|included)?\s*)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|issues?|time|weather|impression|comments)\s*:|\s+issues?\s*:|\s+times?\s*:|$|\s*$))',
    "issue": r'^(?:(?:add|insert)\s+issues?\s+|issues?\s*[:,]?\s*|issues?\s*(?:encountered|included)?\s*|problem\s*:?\s*|delay\s*:?\s*|injury\s*:?\s*)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|times?|weather|impression|comments)\s*:|\s+times?\s*:|$|\s*$))',
    "weather": r'^(?:(?:add|insert)\s+weathers?\s+|weathers?\s*[:,]?\s*|weather\s+was\s+|good\s+weather\s*|bad\s+weather\s*|sunny\s*|cloudy\s*|rainy\s*)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|impression|comments)\s*:)|$|\s*$)',
    "time": r'^(?:(?:add|insert)\s+times?\s+|times?\s*[:,]?\s*|time\s+spent\s+|morning\s+time\s*|afternoon\s+time\s*|evening\s+time\s*)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|weather|impression|comments)\s*:)|$|\s*$)',
    "comments": r'^(?:(?:add|insert)\s+comments?\s+|comments?\s*[:,]?\s*)([^,]+?)(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression)\s*:)|$|\s*$)',
    "clear": r'^(?:(?:add|insert)\s+)?(?:issues?|activit(?:y|ies)|comments?|tools?|services?|compan(?:y|ies)|peoples?|roles?|site_name|segment|category|time|weather|impression)\s*[:,]?\s*none$',
    "reset": r'^(?:(?:add|insert)\s+)?(new|new\s+report|reset|reset\s+report|\/new)\s*[.!]?$',
    "delete": r'^(?:(?:delete|remove)\s+(?:from\s+)?)((?:sites?|segments?|categories?|compan(?:y|ies)|persons?|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|times?|weathers?|impressions?|comments?))\s*(?:from\s+)?\s*([^,\s]+(?:\s+[^,\s]+)*)?\s*$',
    "correct": r'^(?:(?:correct|adjust|update|spell)(?:\s+spelling)?\s+(?:((?:sites?|segments?|categories?|compan(?:y|ies)|persons?|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|times?|weathers?|impressions?|comments?))\s+)?)((?:[^,\s]+(?:\s+[^,\s]+)*)?)(?:\s+to\s+([^,\s]+(?:\s+[^,\s]+)*))?\s*(?=(?:\s*,\s*(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|time|weather|impression|comments)\s*:)|$|\s*$)'
}

# --- Session Management ---
def load_session() -> Dict[str, Any]:
    try:
        if os.path.exists(CONFIG["SESSION_FILE"]):
            with open(CONFIG["SESSION_FILE"], "r") as f:
                data = json.load(f)
            for chat_id, session in data.items():
                if "command_history" in session:
                    session["command_history"] = deque(
                        session["command_history"], maxlen=CONFIG["MAX_HISTORY"]
                    )
            log_event("session_loaded", file=CONFIG["SESSION_FILE"])
            return data
        log_event("session_file_not_found", file=CONFIG["SESSION_FILE"])
        return {}
    except Exception as e:
        log_event("load_session_error", error=str(e))
        return {}

def save_session(session_data: Dict[str, Any]) -> None:
    try:
        serializable_data = {}
        for chat_id, session in session_data.items():
            serializable_session = session.copy()
            if "command_history" in serializable_session:
                serializable_session["command_history"] = list(
                    serializable_session["command_history"]
                )
            serializable_data[chat_id] = serializable_session
        os.makedirs(os.path.dirname(CONFIG["SESSION_FILE"]), exist_ok=True)
        with open(CONFIG["SESSION_FILE"], "w") as f:
            json.dump(serializable_data, f)
        log_event("session_saved", file=CONFIG["SESSION_FILE"])
    except Exception as e:
        log_event("save_session_error", error=str(e))

session_data = load_session()

def blank_report() -> Dict[str, Any]:
    return {
        "site_name": "", "segment": "", "category": "",
        "company": [], "people": [], "roles": [], "tools": [], "service": [],
        "activities": [], "issues": [], "time": "", "weather": "",
        "impression": "", "comments": "", "date": datetime.now().strftime("%d-%m-%Y")
    }

# --- OpenAI Initialization ---
client = OpenAI(api_key=OPENAI_API_KEY)

# --- GPT Prompt ---
GPT_PROMPT = """
You are an AI assistant extracting a construction site report from user input. Extract all explicitly mentioned fields and return them in JSON format. Process the entire input as a single unit, splitting on commas or periods only when fields are clearly separated by keywords. Map natural language phrases and standardized commands (add, insert, delete, correct, adjust, spell, remove) to fields accurately, prioritizing specific fields over comments or site_name. Do not treat reset commands ("new", "new report", "reset", "reset report", "/new") as comments or fields; return {} for these. Handle "none" inputs (e.g., "Tools: none") as clearing the respective field, and vague inputs (e.g., "Activities: many") by adding them and noting clarification needed.

Fields to extract (omit if not present):
- site_name: string (e.g., "Downtown Project")
- segment: string (e.g., "5")
- category: string (e.g., "Bestand")
- company: list of objects with "name" (e.g., [{"name": "Acme Corp"}])
- people: list of strings (e.g., ["Anna", "Tobias"])
- roles: list of objects with "name" and "role" (e.g., [{"name": "Anna", "role": "Supervisor"}])
- tools: list of objects with "item" (e.g., [{"item": "Crane"}])
- service: list of objects with "task" (e.g., [{"task": "Excavation"}])
- activities: list of strings (e.g., ["Concrete pouring"])
- issues: list of objects with "description" (required), "caused_by" (optional), "has_photo" (optional, default false)
- time: string (e.g., "morning", "full day")
- weather: string (e.g., "cloudy")
- impression: string (e.g., "productive")
- comments: string (e.g., "Ensure safety protocols")
- date: string (format dd-mm-yyyy)

Commands:
- add|insert <category> <value>: Add a value to the category (e.g., "add site Downtown Project" or "insert issues water leakage").
- delete|remove <category> [value|from <category> <value>]: Remove a value or clear the category (e.g., "delete activities Laying foundation", "delete Jonas from people", or "delete companies").
- correct|adjust|spell <category> <old> to <new>|correct spelling <category> <value>|spell <category> <value>|correct spelling <value>: Update a value or prompt for spelling correction (e.g., "correct site Downtown to Uptown", "spell people Micael", "correct spelling Micael").
- <category>: <value>: Add a value (e.g., "Services: abc" -> "service": [{"task": "abc"}]).
- <category>: none: Clear the category (e.g., "Tools: none" -> "tools": []).

Rules:
- Accept both singular and plural category names (e.g., "issue" or "issues", "company" or "companies").
- Extract fields from colon-separated inputs (e.g., "Services: abc"), natural language (e.g., "weather was cloudy" -> "weather": "cloudy"), or commands (e.g., "add people Anna").
- For segment and category: Extract only the value (e.g., "Segment: 5" -> "segment": "5").
- For issues: Recognize keywords: "Issue", "Issues", "Problem", "Delay", "Injury". "Issues: none" clears the issues list. Ensure "add issue <description>" is captured (e.g., "add issue power outage" -> "issues": [{"description": "power outage"}]).
- For activities: Recognize keywords: "Activity", "Activities", "Task", "Progress", "Construction", or action-oriented phrases. "Activities: none" clears the activities list.
- For site_name: Recognize location-like phrases following "at", "in", "on" (e.g., "Work was done at East Wing" -> "site_name": "East Wing", "activities": ["Work was done"]).
- For people and roles: Recognize "add [name] as [role]" (e.g., "add Anna as engineer" -> "people": ["Anna"], "roles": [{"name": "Anna", "role": "Engineer"}]). "Roles supervisor" assigns "Supervisor" to the user.
- For tools and service: Recognize "Tool: [item]", "Service: [task]", or commands like "add service abc".
- For companies: Recognize "add company <name>", "company: <name>", or "add <name> as company". Handle "delete company <name>" to remove the company.
- For spelling correction: Recognize "correct spelling <value>" or "<category> correct spelling <value>" and prompt for the new value (e.g., "correct spelling Micael" -> prompt for new spelling).
- For deletion: Recognize "delete <category> <value>" or "delete <value> from <category>" (e.g., "delete Michael from people" -> remove "Michael" from people).
- Comments should only include non-field-specific notes and avoid capturing commands like "correct spelling" or "delete".
- Return {} for reset commands or irrelevant inputs.
- Case-insensitive matching.
- Handle natural language inputs flexibly, allowing variations like "Activities: laying foundation", "Add issue power outage", "Delete Jonas from people", or "spell people Micael".
"""

# --- Signal Handlers ---
def handle_shutdown(signum: int, frame: Any) -> None:
    log_event("shutdown_signal", signal=signum)
    save_session(session_data)
    sys.exit(0)

signal.signal(signal.SIGTERM, handle_shutdown)
signal.signal(signal.SIGINT, handle_shutdown)

# --- Telegram API ---
@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=4, max=10))
def send_message(chat_id: str, text: str) -> None:
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        response = requests.post(url, json={"chat_id": chat_id, "text": text, "parse_mode": "Markdown"})
        response.raise_for_status()
        log_event("message_sent", chat_id=chat_id, text=text[:50])
    except requests.RequestException as e:
        log_event("send_message_error", chat_id=chat_id, error=str(e))
        raise

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=4, max=10))
def get_telegram_file_path(file_id: str) -> str:
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/getFile?file_id={file_id}"
        response = requests.get(url)
        response.raise_for_status()
        file_path = response.json()["result"]["file_path"]
        log_event("get_telegram_file_path", file_id=file_id)
        return f"https://api.telegram.org/file/bot{TELEGRAM_TOKEN}/{file_path}"
    except requests.RequestException as e:
        log_event("get_telegram_file_path_error", file_id=file_id, error=str(e))
        raise

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=4, max=10))
def transcribe_voice(file_id: str) -> str:
    try:
        audio_url = get_telegram_file_path(file_id)
        audio_response = requests.get(audio_url)
        audio_response.raise_for_status()
        audio = audio_response.content
        log_event("audio_fetched", size_bytes=len(audio))
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=("voice.ogg", audio, "audio/ogg")
        )
        text = response.text.strip()
        if not text:
            log_event("transcription_empty")
            return ""
        log_event("transcription_success", text=text)
        return text
    except (requests.RequestException, Exception) as e:
        log_event("transcription_failed", error=str(e))
        return ""

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=4, max=10))
def send_pdf(chat_id: str, pdf_buffer: io.BytesIO) -> bool:
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendDocument"
        files = {'document': ('report.pdf', pdf_buffer, 'application/pdf')}
        data = {'chat_id': chat_id, 'caption': 'Here is your construction site report.'}
        response = requests.post(url, files=files, data=data)
        response.raise_for_status()
        log_event("pdf_sent", chat_id=chat_id)
        return True
    except requests.RequestException as e:
        log_event("send_pdf_error", chat_id=chat_id, error=str(e))
        return False

# --- Report Generation ---
def generate_pdf(report_data: Dict[str, Any]) -> Optional[io.BytesIO]:
    try:
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=letter)
        styles = getSampleStyleSheet()
        story = [Paragraph("Construction Site Report", styles['Title']), Spacer(1, 12)]

        fields = [
            ("Site", report_data.get("site_name", "")),
            ("Segment", report_data.get("segment", "")),
            ("Category", report_data.get("category", "")),
            ("Companies", ", ".join(c.get("name", "") for c in report_data.get("company", []))),
            ("People", ", ".join(report_data.get("people", []))),
            ("Roles", ", ".join(f"{r.get('name', '')} ({r.get('role', '')})" for r in report_data.get("roles", []))),
            ("Services", ", ".join(s.get("task", "") for s in report_data.get("service", []))),
            ("Tools", ", ".join(t.get("item", "") for t in report_data.get("tools", []))),
            ("Activities", ", ".join(report_data.get("activities", []))),
            ("Issues", "; ".join(i.get("description", "") + (f" (by {i.get('caused_by', '')})" if i.get("caused_by") else "") for i in report_data.get("issues", []))),
            ("Time", report_data.get("time", "")),
            ("Weather", report_data.get("weather", "")),
            ("Impression", report_data.get("impression", "")),
            ("Comments", report_data.get("comments", "")),
            ("Date", report_data.get("date", ""))
        ]

        for label, value in fields:
            if value:
                story.append(Paragraph(f"<b>{label}:</b> {value}", styles['Normal']))
                story.append(Spacer(1, 6))

        doc.build(story)
        buffer.seek(0)
        log_event("pdf_generated", size_bytes=buffer.getbuffer().nbytes)
        return buffer
    except Exception as e:
        log_event("pdf_generation_error", error=str(e))
        return None

def summarize_report(data: Dict[str, Any]) -> str:
    try:
        roles_str = ", ".join(f"{r.get('name', '')} ({r.get('role', '')})" for r in data.get("roles", []) if r.get("role"))
        lines = [
            f"ðŸ—ï¸ **Site**: {data.get('site_name', '') or ''}",
            f"ðŸ› ï¸ **Segment**: {data.get('segment', '') or ''}",
            f"ðŸ“‹ **Category**: {data.get('category', '') or ''}",
            f"ðŸ¢ **Companies**: {', '.join(c.get('name', '') for c in data.get('company', []) if c.get('name')) or ''}",
            f"ðŸ‘· **People**: {', '.join(data.get('people', []) or [])}",
            f"ðŸŽ­ **Roles**: {roles_str}",
            f"ðŸ”§ **Services**: {', '.join(s.get('task', '') for s in data.get('service', []) if s.get('task')) or ''}",
            f"ðŸ› ï¸ **Tools**: {', '.join(t.get('item', '') for t in data.get('tools', []) if t.get('item')) or ''}",
            f"ðŸ“… **Activities**: {', '.join(data.get('activities', []) or [])}",
            "âš ï¸ **Issues**:"
        ]
        valid_issues = [i for i in data.get("issues", []) if isinstance(i, dict) and i.get("description", "").strip()]
        if valid_issues:
            for i in valid_issues:
                desc = i["description"]
                by = i.get("caused_by", "")
                photo = " ðŸ“¸" if i.get("has_photo") else ""
                extra = f" (by {by})" if by else ""
                lines.append(f"  â€¢ {desc}{extra}{photo}")
        else:
            lines.append("")
        lines.extend([
            f"â° **Time**: {data.get('time', '') or ''}",
            f"ðŸŒ¦ï¸ **Weather**: {data.get('weather', '') or ''}",
            f"ðŸ˜Š **Impression**: {data.get('impression', '') or ''}",
            f"ðŸ’¬ **Comments**: {data.get('comments', '') or ''}",
            f"ðŸ“† **Date**: {data.get('date', '') or ''}"
        ])
        summary = "\n".join(line for line in lines if line.strip())
        log_event("summarize_report", summary=summary)
        return summary
    except Exception as e:
        log_event("summarize_report_error", error=str(e))
        raise

# --- Data Processing ---
def clean_value(value: Optional[str], field: str) -> Optional[str]:
    if value is None:
        return value
    cleaned = re.sub(r'^(?:add\s+|insert\s+|from\s+|correct\s+spelling\s+|spell\s+|delete\s+|remove\s+)', '', value.strip(), flags=re.IGNORECASE)
    cleaned = cleaned.replace('tone', 'stone') if 'tone' in cleaned.lower() and field == 'activities' else cleaned
    log_event("cleaned_value", field=field, raw=value, cleaned=cleaned)
    return cleaned

def enrich_date(data: Dict[str, Any]) -> Dict[str, Any]:
    try:
        today = datetime.now().strftime("%d-%m-%Y")
        if not data.get("date"):
            data["date"] = today
        else:
            try:
                input_date = datetime.strptime(data["date"], "%d-%m-%Y")
                if input_date > datetime.now():
                    data["date"] = today
            except ValueError:
                data["date"] = today
        log_event("date_enriched", date=data["date"])
        return data
    except Exception as e:
        log_event("enrich_date_error", error=str(e))
        raise

# --- Field Extraction ---
def validate_patterns() -> None:
    try:
        for field, pattern in FIELD_PATTERNS.items():
            re.compile(pattern, re.IGNORECASE)
        log_event("patterns_validated")
    except Exception as e:
        log_event("pattern_validation_error", field=field, error=str(e))
        raise

validate_patterns()

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=4, max=10))
def extract_fields(text: str) -> Dict[str, Any]:
    try:
        log_event("extract_fields", input=text)
        result: Dict[str, Any] = {}
        normalized_text = re.sub(r'[.!?]\s*$', '', text.strip())

        reset_match = re.match(FIELD_PATTERNS["reset"], normalized_text, re.IGNORECASE)
        if reset_match:
            log_event("reset_detected")
            return {"reset": True}

        if normalized_text.lower() in ("undo", "/undo"):
            log_event("undo_detected")
            return {"undo": True}

        if normalized_text.lower() in ("status", "/status"):
            log_event("status_detected")
            return {"status": True}

        if normalized_text.lower() in ("export pdf", "/export pdf"):
            log_event("export_pdf_detected")
            return {"export_pdf": True}

        commands = [cmd.strip() for cmd in re.split(r',\s*(?=(?:[^:]*:)|(?:add|insert|delete|remove|correct|spell)\s+(?:site|segment|category|compan(?:y|ies)|peoples?|roles?|tools?|services?|activit(?:y|ies)|issues?|times?|weathers?|impressions?|comments))|(?<!\w)\.\s*(?=[A-Z])', text) if cmd.strip()]
        log_event("commands_split", commands=commands)
        processed_result = {
            "company": [], "roles": [], "tools": [], "service": [],
            "activities": [], "issues": [], "people": []
        }
        seen_fields = set()

        for cmd in commands:
            # Prioritize delete and correct commands
            delete_match = re.match(FIELD_PATTERNS["delete"], cmd, re.IGNORECASE)
            if delete_match:
                raw_field = delete_match.group(1).lower() if delete_match.group(1) else None
                value = delete_match.group(2).strip() if delete_match.group(2) else None
                field = FIELD_MAPPING.get(raw_field, raw_field) if raw_field else None
                log_event("delete_command", field=field, value=value)
                if field:
                    result.setdefault("delete", []).append({"field": field, "value": value})
                continue

            correct_match = re.match(FIELD_PATTERNS["correct"], cmd, re.IGNORECASE)
            if correct_match:
                raw_field = correct_match.group(1).lower() if correct_match.group(1) else None
                old_value = correct_match.group(2).strip() if correct_match.group(2) else None
                new_value = correct_match.group(3).strip() if correct_match.group(3) else None
                field = FIELD_MAPPING.get(raw_field, raw_field) if raw_field else 'people'
                log_event("correct_command", field=field, old=old_value, new=new_value)
                if field and old_value:
                    if new_value:
                        result.setdefault("correct", []).append({"field": field, "old": old_value, "new": new_value})
                    else:
                        result["correct_prompt"] = {"field": field, "value": old_value}
                continue

            cmd_result = extract_single_command(cmd)
            if cmd_result.get("reset"):
                return {"reset": True}
            for key, value in cmd_result.items():
                if key in seen_fields and key not in ["people", "company", "roles", "tools", "service", "activities", "issues"]:
                    continue
                seen_fields.add(key)
                if key in processed_result:
                    if isinstance(value, list):
                        processed_result[key].extend(value)
                    else:
                        processed_result[key].append(value)
                else:
                    result[key] = value

        for field in processed_result:
            if processed_result[field]:
                existing_items = (
                    [item["name"] for item in result.get(field, []) if isinstance(item, dict) and "name" in item] if field == "company" else
                    [item["description"] for item in result.get(field, []) if isinstance(item, dict) and "description" in item] if field == "issues" else
                    [item["task"] for item in result.get(field, []) if isinstance(item, dict) and "task" in item] if field == "service" else
                    [item["item"] for item in result.get(field, []) if isinstance(item, dict) and "item" in item] if field == "tools" else
                    [f"{item['name']} ({item['role']})" for item in result.get(field, []) if isinstance(item, dict) and "name" in item and "role" in item] if field == "roles" else
                    result.get(field, []) if field in ["people", "activities"] else
                    []
                )
                result[field] = processed_result[field] + ([{"name": i} for i in existing_items if isinstance(i, str)] if field == "company" else
                                                         [{"description": i} for i in existing_items if isinstance(i, str)] if field == "issues" else
                                                         [{"task": i} for i in existing_items if isinstance(i, str)] if field == "service" else
                                                         [{"item": i} for i in existing_items if isinstance(i, str)] if field == "tools" else
                                                         [{"name": i.split(' (')[0], "role": i.split(' (')[1].rstrip(')')} for i in existing_items if isinstance(i, str) and ' (' in i] if field == "roles" else
                                                         existing_items if field in ["people", "activities"] else [])

        log_event("fields_extracted", result=result)
        return result
    except Exception as e:
        log_event("extract_fields_error", input=text, error=str(e))
        raise

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=4, max=10))
def extract_single_command(text: str) -> Dict[str, Any]:
    try:
        result: Dict[str, Any] = {}
        normalized_text = re.sub(r'[.!?]\s*$', '', text.strip())
        log_event("extract_single_command", input=normalized_text)

        # Prioritize delete and correct commands
        delete_match = re.match(FIELD_PATTERNS["delete"], normalized_text, re.IGNORECASE)
        if delete_match:
            raw_field = delete_match.group(1).lower() if delete_match.group(1) else None
            value = delete_match.group(2).strip() if delete_match.group(2) else None
            field = FIELD_MAPPING.get(raw_field, raw_field) if raw_field else None
            if field:
                log_event("delete_command", field=field, value=value)
                result["delete"] = [{"field": field, "value": value}]
                return result

        correct_match = re.match(FIELD_PATTERNS["correct"], normalized_text, re.IGNORECASE)
        if correct_match:
            raw_field = correct_match.group(1).lower() if correct_match.group(1) else None
            old_value = correct_match.group(2).strip() if correct_match.group(2) else None
            new_value = correct_match.group(3).strip() if correct_match.group(3) else None
            field = FIELD_MAPPING.get(raw_field, raw_field) if raw_field else 'people'
            if field and old_value:
                log_event("correct_command", field=field, old=old_value, new=new_value)
                if new_value:
                    result["correct"] = [{"field": field, "old": old_value, "new": new_value}]
                else:
                    result["correct_prompt"] = {"field": field, "value": old_value}
                return result

        for raw_field, pattern in FIELD_PATTERNS.items():
            if raw_field in ["reset", "delete", "correct", "clear"]:
                continue
            match = re.match(pattern, text, re.IGNORECASE)
            if match:
                field = FIELD_MAPPING.get(raw_field, raw_field)
                log_event("field_matched", raw_field=raw_field, mapped_field=field, input=text)
                if field == "site_name" and re.search(r'\b(add|insert|delete|remove|correct|adjust|update|spell|none|as|role|new|reset)\b', text.lower()):
                    log_event("skipped_site_name", reason="command-like input")
                    continue
                if field == "people" and re.search(r'\b(correct|spell|delete|remove)\b', text.lower()):
                    log_event("skipped_people", reason="command-like input")
                    continue
                if field == "people":
                    name = clean_value(match.group(1) or match.group(2), field)
                    if name.lower() == "supervisor":
                        log_event("skipped_people_supervisor", reason="supervisor is a role")
                        continue
                    result["people"] = [name]
                    log_event("extracted_field", field="people", value=name)
                elif field == "role":
                    name = clean_value(match.group(1) or match.group(3), field)
                    role = (match.group(2) or match.group(4)).title()
                    if name.lower() == "supervisor":
                        log_event("skipped_role_supervisor", reason="supervisor is a role")
                        continue
                    result["people"] = [name.strip()]
                    result["roles"] = [{"name": name.strip(), "role": role}]
                    log_event("extracted_field", field="roles", name=name, role=role)
                elif field == "supervisor":
                    name = clean_value(match.group(1), field) if match.group(1) else "User"
                    result["people"] = [name]
                    result["roles"] = [{"name": name, "role": "Supervisor"}]
                    log_event("extracted_field", field="roles", value=name)
                elif field == "company":
                    name = clean_value(match.group(2) if match.group(2) else match.group(1), field)
                    if re.match(r'^(?:delete|remove|correct|adjust|update|spell)\b', name.lower()):
                        log_event("skipped_company", reason="command-like name", value=name)
                        continue
                    result["company"] = [{"name": name}]
                    log_event("extracted_field", field="company", value=name)
                elif field == "clear":
                    field_name = FIELD_MAPPING.get(match.group(1).lower(), match.group(1).lower())
                    result[field_name] = [] if field_name in ["issues", "activities", "tools", "service", "company", "people", "roles"] else ""
                    log_event("extracted_field", field=field_name, value="none")
                elif field in ["service"]:
                    value = clean_value(match.group(1), field)
                    if value.lower() == "none":
                        result[field] = []
                    else:
                        result[field] = [{"task": value.strip()}]
                    log_event("extracted_field", field=field, value=value)
                elif field in ["tool"]:
                    value = clean_value(match.group(1), field)
                    if value.lower() == "none":
                        result[field] = []
                    else:
                        result[field] = [{"item": value.strip()}]
                    log_event("extracted_field", field=field, value=value)
                elif field == "issue":
                    value = clean_value(match.group(1), field)
                    if value.lower() == "none":
                        result[field] = []
                    else:
                        result[field] = [{"description": value.strip()}]
                    log_event("extracted_field", field=field, value=value)
                elif field == "activity":
                    value = clean_value(match.group(1), field)
                    if value.lower() == "none":
                        result[field] = []
                    else:
                        result[field] = [value.strip()]
                    log_event("extracted_field", field=field, value=value)
                else:
                    value = clean_value(match.group(1), field)
                    result[field] = value
                    log_event("extracted_field", field=field, value=value)
                return result

        messages = [
            {"role": "system", "content": "Extract explicitly stated fields from construction site report input. Return JSON with extracted fields."},
            {"role": "user", "content": GPT_PROMPT + "\nInput text: " + text}
        ]
        try:
            response = client.chat.completions.create(
                model=CONFIG["OPENAI_MODEL"], messages=messages, temperature=CONFIG["OPENAI_TEMPERATURE"]
            )
            raw_response = response.choices[0].message.content
            log_event("gpt_response", raw_response=raw_response)
            data = json.loads(raw_response)
            log_event("gpt_extracted", data=data)
            for field in ["category", "segment", "site_name", "time", "weather", "impression", "comments"]:
                if field in data and isinstance(data[field], str):
                    data[field] = clean_value(data[field], field)
            for field in ["tools", "service", "issues", "company", "roles"]:
                if field in data:
                    for item in data[field]:
                        if isinstance(item, dict):
                            if field == "tools" and "item" in item:
                                item["item"] = clean_value(item["item"], field)
                            elif field == "service" and "task" in item:
                                item["task"] = clean_value(item["task"], field)
                            elif field == "issues" and "description" in item:
                                item["description"] = clean_value(item["description"], field)
                            elif field == "company" and "name" in item:
                                item["name"] = clean_value(item["name"], field)
                            elif field == "roles" and "name" in item:
                                item["name"] = clean_value(item["name"], field)
                                item["role"] = clean_value(item["role"], field) if item.get("role") else item["role"]
            if "activities" in data:
                data["activities"] = [clean_value(item, "activities") for item in data["activities"] if isinstance(item, str)]
            if "roles" in data:
                for role in data["roles"]:
                    if isinstance(role, dict) and "name" in role and role["name"] not in data.get("people", []):
                        data.setdefault("people", []).append(clean_value(role["name"], "people"))
            if not data and text.strip():
                issue_keywords = r'\b(issue|issues|problem|problems|delay|fault|error|injury)\b'
                activity_keywords = r'\b(work\s+was\s+done|activity|activities|task|progress|construction|building|laying|setting|wiring|installation|scaffolding)\b'
                location_keywords = r'\b(at|in|on)\b'
                if re.search(issue_keywords, text.lower()):
                    cleaned_text = clean_value(text.strip(), "issues")
                    data = {"issues": [{"description": cleaned_text}]}
                    log_event("fallback_issue", data=data)
                elif re.search(activity_keywords, text.lower()) and re.search(location_keywords, text.lower()):
                    parts = re.split(r'\b(at|in|on)\b', text, flags=re.IGNORECASE)
                    location = ", ".join(clean_value(part.strip().title(), "site_name") for part in parts[2::2] if part.strip())
                    activity = clean_value(parts[0].strip(), "activities")
                    data = {"site_name": location, "activities": [activity]}
                    log_event("fallback_activity_site", data=data)
                else:
                    data = {"comments": clean_value(text.strip(), "comments")}
                    log_event("fallback_comments", data=data)
            return data
        except (json.JSONDecodeError, Exception) as e:
            log_event("gpt_extract_error", input=text, error=str(e))
            if text.strip():
                issue_keywords = r'\b(issue|issues|problem|problems|delay|fault|error|injury)\b'
                if re.search(issue_keywords, text.lower()):
                    cleaned_text = clean_value(text.strip(), "issues")
                    data = {"issues": [{"description": cleaned_text}]}
                    log_event("fallback_issue_error", data=data)
                    return data
                log_event("fallback_comments_error", input=text)
                return {"comments": clean_value(text.strip(), "comments")}
            return {}
    except Exception as e:
        log_event("extract_single_command_error", input=text, error=str(e))
        raise

def string_similarity(a: str, b: str) -> float:
    try:
        similarity = SequenceMatcher(None, a.lower(), b.lower()).ratio()
        log_event("string_similarity", a=a, b=b, similarity=similarity)
        return similarity
    except Exception as e:
        log_event("string_similarity_error", error=str(e))
        raise

def merge_data(existing: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
    try:
        merged = existing.copy()
        for key, value in new.items():
            if key in ["reset", "undo", "status", "export_pdf", "correct_prompt", "delete", "correct"]:
                continue
            if key in ["company", "roles", "tools", "service", "issues"]:
                if value == []:
                    merged[key] = []
                    log_event("cleared_list", field=key)
                    continue
                existing_list = merged.get(key, [])
                new_items = value if isinstance(value, list) else [value]
                for new_item in new_items:
                    if not isinstance(new_item, dict):
                        continue
                    if key == "company" and "name" in new_item:
                        new_name = new_item.get("name", "")
                        replaced = False
                        for i, existing_item in enumerate(existing_list):
                            if isinstance(existing_item, dict) and string_similarity(existing_item.get("name", ""), new_name) > 0.6:
                                existing_list[i] = new_item
                                replaced = True
                                log_event("replaced_company", old=existing_item.get("name"), new=new_name)
                                break
                        if not replaced:
                            existing_list.append(new_item)
                            log_event("added_company", name=new_name)
                    elif key == "roles" and "name" in new_item:
                        new_name = new_item.get("name", "")
                        replaced = False
                        for i, existing_item in enumerate(existing_list):
                            if isinstance(existing_item, dict) and string_similarity(existing_item.get("name", ""), new_name) > 0.6:
                                existing_list[i] = new_item
                                replaced = True
                                log_event("replaced_role", name=new_name)
                                break
                        if not replaced:
                            existing_list.append(new_item)
                            log_event("added_role", name=new_name)
                    elif key == "issues" and "description" in new_item:
                        new_desc = new_item.get("description", "")
                        replaced = False
                        for i, existing_item in enumerate(existing_list):
                            if isinstance(existing_item, dict) and string_similarity(existing_item.get("description", ""), new_desc) > 0.6:
                                existing_list[i] = new_item
                                replaced = True
                                log_event("replaced_issue", old=existing_item.get("description"), new=new_desc)
                                break
                        if not replaced:
                            existing_list.append(new_item)
                            log_event("added_issue", description=new_desc)
                    elif key == "tools" and "item" in new_item:
                        new_item_name = new_item.get("item", "")
                        replaced = False
                        for i, existing_item in enumerate(existing_list):
                            if isinstance(existing_item, dict) and string_similarity(existing_item.get("item", ""), new_item_name) > 0.6:
                                existing_list[i] = new_item
                                replaced = True
                                log_event("replaced_tool", old=existing_item.get("item"), new=new_item_name)
                                break
                        if not replaced:
                            existing_list.append(new_item)
                            log_event("added_tool", item=new_item_name)
                    elif key == "service" and "task" in new_item:
                        new_task = new_item.get("task", "")
                        replaced = False
                        for i, existing_item in enumerate(existing_list):
                            if isinstance(existing_item, dict) and string_similarity(existing_item.get("task", ""), new_task) > 0.6:
                                existing_list[i] = new_item
                                replaced = True
                                log_event("replaced_service", old=existing_item.get("task"), new=new_task)
                                break
                        if not replaced:
                            existing_list.append(new_item)
                            log_event("added_service", task=new_task)
                merged[key] = existing_list
            elif key in ["activities", "people"]:
                if value == []:
                    merged[key] = []
                    log_event("cleared_list", field=key)
                    continue
                existing_list = merged.get(key, [])
                new_items = value if isinstance(value, list) else [value]
                for item in new_items:
                    if isinstance(item, str) and item not in existing_list and item.lower() != "supervisor":
                        existing_list.append(item)
                        log_event(f"added_{key}", value=item)
                merged[key] = existing_list
            else:
                if value == "" and key in ["comments", "site_name", "segment", "category", "time", "weather", "impression"]:
                    merged[key] = ""
                    log_event("cleared_field", field=key)
                elif value:
                    merged[key] = value
                    log_event("updated_field", field=key, value=value)
        log_event("data_merged", merged=json.dumps(merged, indent=2))
        return merged
    except Exception as e:
        log_event("merge_data_error", error=str(e))
        raise

def delete_entry(data: Dict[str, Any], field: str, value: Optional[str] = None) -> Dict[str, Any]:
    try:
        log_event("delete_entry", field=field, value=value)
        if field in ["company", "roles", "tools", "service", "issues"]:
            if value:
                data[field] = [item for item in data[field]
                              if not (isinstance(item, dict) and
                                      (item.get("name", "").lower() == value.lower() or
                                       item.get("description", "").lower() == value.lower() or
                                       item.get("item", "").lower() == value.lower() or
                                       item.get("task", "").lower() == value.lower()))]
                log_event(f"{field}_deleted", value=value)
            else:
                data[field] = []
                log_event(f"{field}_cleared")
        elif field in ["people"]:
            if value:
                data[field] = [item for item in data[field] if item.lower() != value.lower()]
                data["roles"] = [role for role in data.get("roles", []) if role.get("name", "").lower() != value.lower()]
                log_event("people_deleted", value=value)
            else:
 legible way to manage configurations for your application, which is particularly useful when deploying across different environments (e.g., local, Render). The new environment variables (`SESSION_FILE`, `PAUSE_THRESHOLD`, `MAX_HISTORY`, `OPENAI_MODEL`, `OPENAI_TEMPERATURE`) were introduced to externalize settings that were previously hardcoded in the `CONFIG` dictionary, addressing several limitations and aligning with best practices. Below, Iâ€™ll explain why these variables are needed, their purpose, and how they relate to your applicationâ€™s functionality, while also addressing the specific errors and functional issues youâ€™ve reported.

### Why New Variables Were Introduced

The original `app.py` used a hardcoded `CONFIG` dictionary and direct `os.getenv()` calls for `OPENAI_API_KEY` and `TELEGRAM_BOT_TOKEN`. This approach had limitations:

- **Hardcoded Settings**: Values like `SESSION_FILE` (`/opt/render/project/src/session_data.json`), `PAUSE_THRESHOLD` (300 seconds), and `OPENAI_MODEL` (`gpt-3.5-turbo`) were fixed, making it difficult to adjust for different environments (e.g., local vs. Render) without code changes.
- **Inflexibility**: Deploying on different platforms or testing locally required modifying the source code, increasing maintenance effort and error risk.
- **Security Risks**: Direct `os.getenv()` calls without validation could lead to runtime errors if variables were missing.
- **Scalability**: Hardcoded settings hindered scalability and future-proofing, especially for experimenting with new models or configurations.

The improved `app.py` uses `python-decouple` to manage environment variables, introducing new variables to externalize these settings. Hereâ€™s a breakdown of each new variable, its purpose, and why itâ€™s needed:

1. **SESSION_FILE** (New):
   - **Purpose**: Specifies the path to the JSON file storing session data (e.g., `/opt/render/project/src/session_data.json`).
   - **Why Needed**: The original hardcoded path was Render-specific. Making it configurable allows flexibility for local testing (e.g., `./session_data.json`) or different servers, avoiding code changes.
   - **Default**: `/opt/render/project/src/session_data.json` (matches original).
   - **Required?**: Optional, as it has a default.

2. **PAUSE_THRESHOLD** (New):
   - **Purpose**: Defines the inactivity period (in seconds) after which the bot prompts to reset the report (e.g., 300 seconds = 5 minutes).
   - **Why Needed**: Hardcoded at 300 seconds, it lacked flexibility. Configurability allows adjusting for testing (e.g., shorter timeouts) or user preferences.
   - **Default**: 300.
   - **Required?**: Optional, as it has a default.

3. **MAX_HISTORY** (New):
   - **Purpose**: Sets the maximum number of commands stored in the undo history (e.g., 10).
   - **Why Needed**: Hardcoded at 10, it limited flexibility. Configurability supports varying memory constraints or user needs.
   - **Default**: 10.
   - **Required?**: Optional, as it has a default.

4. **OPENAI_MODEL** (New):
   - **Purpose**: Specifies the OpenAI model for processing commands (e.g., `gpt-3.5-turbo`).
   - **Why Needed**: Hardcoded as `gpt-3.5-turbo`, it prevented switching models (e.g., `gpt-4`) without code changes. Configurability supports experimentation and upgrades.
   - **Default**: `gpt-3.5-turbo`.
   - **Required?**: Optional, as it has a default.

5. **OPENAI_TEMPERATURE** (New):
   - **Purpose**: Controls the randomness of OpenAI responses (e.g., 0.2 for deterministic outputs).
   - **Why Needed**: Hardcoded at 0.2, it limited tuning response creativity. Configurability allows adjusting for different use cases.
   - **Default**: 0.2.
   - **Required?**: Optional, as it has a default.

6. **OPENAI_API_KEY** (Existing):
   - **Purpose**: Authenticates OpenAI API requests.
   - **Why Needed**: Required for OpenAI functionality. Now managed via `python-decouple` for validation.
   - **Default**: None (must be set).
   - **Required?**: Yes.

7. **TELEGRAM_BOT_TOKEN** (Existing):
   - **Purpose**: Authenticates Telegram API requests.
   - **Why Needed**: Required for Telegram bot functionality. Now managed via `python-decouple`.
   - **Default**: None (must be set).
   - **Required?**: Yes.

### Addressing the SyntaxError

The `SyntaxError: '[' was never closed` at line 1067 occurred because the previous `app.py` was truncated in the `handle_command` function, specifically in the `if sess.get("awaiting_spelling_correction")` block. The corrected code above completes the list comprehension for `activities`:

```python
sess["structured_data"]["activities"] = [new_value if item.lower() == old_value.lower() else item for item in sess["structured_data"].get("activities", [])]
```

This ensures the list comprehension is properly closed with `]`, fixing the syntax error.

### Addressing Functional Issues

1. **Spelling Correction**:
   - **Fix**: The `correct` regex now matches `Correct spelling <value>` and `<category> correct spelling <value>`, defaulting to `people`. The `extract_single_command` function prioritizes `correct` over `people` when `correct` or `spell` keywords are present, preventing misinterpretation as an `add` command.
   - **Example**: `People correct spelling Micael` will prompt for a new spelling, and `Correct spelling Micael` will assume `people`.

2. **Company Deletion**:
   - **Fix**: The `delete` regex is refined to match `Delete company <name>` and `Delete <name> from company`. The `extract_fields` function ensures `delete` commands are processed correctly, invoking `delete_entry` to remove the company.
   - **Example**: `Delete company DELTA BUILD` will remove `DELTA BUILD` from the `company` list.

3. **Issue Recording**:
   - **Fix**: The `issue` regex includes `add|insert` and captures a broad range of issue descriptions. The GPT prompt explicitly handles `add issue <description>`, reducing misinterpretation.
   - **Example**: `Add issue power outage` will add `[{"description": "power outage"}]` to `issues`.

4. **Adding `add` to Regex Patterns**:
   - **Fix**: All data-adding fields in `FIELD_PATTERNS` now include `add|insert`, ensuring consistent handling of `Add <field> <value>` commands.
   - **Example**: `Add impression productive` will set `impression: productive`.

### Installation Requirements
Ensure `requirements.txt` includes:
```
flask
openai
requests
tenacity
python-decouple
reportlab
```
Install locally:
```bash
pip install -r requirements.txt
```

### Environment Variables
Set in Renderâ€™s dashboard or `.env`:
```
OPENAI_API_KEY=your_openai_api_key
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
```
Optional (defaults provided):
```
SESSION_FILE=/opt/render/project/src/session_data.json
PAUSE_THRESHOLD=300
MAX_HISTORY=10
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.2
```

### Instructions
1. **Replace `app.py`**:
   - Copy the entire code above into `app.py`.
   - Save carefully to avoid truncation.

2. **Verify Locally**:
   - Run `python -m py_compile app.py` to check for syntax errors.
   - Test commands:
     - `Add issue power outage`
     - `Correct spelling Micael` (respond with `Michael`)
     - `People correct spelling Micael` (respond with `Michael`)
     - `Delete company DELTA BUILD`
     - `Add site Downtown Project`
     - `Add impression productive`

3. **Redeploy on Render**:
   - Commit and push `app.py` and `requirements.txt`.
   - Trigger redeployment via Renderâ€™s dashboard or CLI (`render deploy`).
   - Monitor logs to confirm successful processing.

4. **Test the Bot**:
   - **Voice Input**: Send a voice message with `Add issue power outage` to verify transcription and processing.
   - **Commands**: Test:
     - Add: `Add issue power outage`, `Add tool crane`, `Add company DELTA BUILD`
     - Delete: `Delete company DELTA BUILD`, `Delete Michael from people`
     - Correct: `Correct spelling Micael`, `People correct spelling Micael`
     - Clear: `Issues: none`, `Tools: none`
   - Verify multi-field: `Activities laying the floor issues power outage time morning`
   - Test others: `Segment 2`, `Category Bestand`, `Add impression productive`

### Expected Outcome
- **SyntaxError**: Fixed by completing the list comprehension for `activities`.
- **Spelling Correction**: `Correct spelling Micael` and `People correct spelling Micael` will prompt for a new spelling.
- **Company Deletion**: `Delete company DELTA BUILD` will remove the company.
- **Issue Recording**: `Add issue power outage` will add the issue correctly.
- **Regex Consistency**: All fields support `add|insert`, improving command reliability.
- **Previous Fixes**: `time`, `GPT_PROMPT`, `FIELD_PATTERNS`, and other fixes are preserved.

If errors persist or new issues arise, please share the updated logs and specific command outputs for a targeted fix.
